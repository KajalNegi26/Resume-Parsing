{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5PqKIB8Uf9F"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "veBCTEPCaIiK",
        "outputId": "b32cf239-1561-4140-c766-99c357aee010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PueaXoOzUtsK",
        "outputId": "b916ab49-d273-4e35-e1a2-beaf2227c57e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n"
          ]
        }
      ],
      "source": [
        "pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jho35IyAUt4R",
        "outputId": "cf1e7e1d-4461-4414-c805-39c5836922ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.11/dist-packages (0.11.6)\n",
            "Requirement already satisfied: pdfminer.six==20250327 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (20250327)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.2.1)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (4.30.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.22)\n"
          ]
        }
      ],
      "source": [
        "pip install pdfplumber"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UqifJtnUt7H"
      },
      "outputs": [],
      "source": [
        "import PyPDF2, pdfplumber"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjVowhDpUt-I"
      },
      "outputs": [],
      "source": [
        "CV=\"/content/DIVYANSHU (1).pdf\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJnSEaoUVQgF"
      },
      "outputs": [],
      "source": [
        "\n",
        "CV_File=open(CV,'rb')\n",
        "Script=PyPDF2.PdfReader(CV_File)\n",
        "pages=len(Script.pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8ype9J2Wpns",
        "outputId": "17504f60-4f53-42cd-ceb8-c9215b61fe82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DIVYANSHU\n",
            "EDUCATION\n",
            "Graphic Era Hill University 2021-2025\n",
            "B.Tech Computer Science Current GPA: 7.5\n",
            "Amenity Public School (High School and Intermediate School)\n",
            "COURSEWORK\n",
            "Courses: Object-Oriented Programming, Data Science: Machine Learning(pl.haravard.edu),The Complete\n",
            "2023Web Development Bootcamp\n",
            "SKILLS\n",
            "Languages: C/C++, Python,JavaScript, HTML/CSS\n",
            "Tools: Git/GitHub, VS Code, PyCharm, StackOverflow\n",
            "Frameworks: Bootstrap, Node.Js, React.Js\n",
            "Operating Systems: Windows, Ubuntu ,Macintosh\n",
            "PROJECTS\n",
            "Brain Tumour Detection using CNN and Transfer Learning Technique | Tensorflow, Keras, Python, VGG16\n",
            "• Brain Tumour detection system utilizing Convolutional Neural Networks (CNN) and the VGG16 algorithm\n",
            "• Trained on a Kaggle dataset, the model accurately identifies tumour through MRI scans of brain.\n",
            "Credit Card Fraud Detection using ML | Linear Regression , Decesion Tree, K-Nearest Neighbors (KNN)\n",
            "• Created a model to classify wether a transaction is fraudlent or not among allCredit Card Transactions.\n",
            "Stock Price Prediction | CNN,ANN,LSTM\n",
            "• The model Predicts closing price of the stock and plot graphs between the actual price amd predicted price.\n",
            "POSITION OF RESPONSIBILITY\n",
            "Head Designer\n",
            "ACM-GEHU\n",
            "Lead a team of graphic designerss and tech enthusiast to organise hackathons and coding events in college\n",
            "Membership Chair of ACM Student chapter\n",
            "Conduct important workshops, coding exams in our college\n",
            "ACHIEVEMENTS\n",
            "Succesfully completed program on Artificial Intelligence with python from Coincent\n",
            "150+ DSA Questions in LeetCode and 90+ Questions in GeeksforGeeks\n",
            "Runner up in Rotary Club debate competition.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "Script = []\n",
        "with pdfplumber.open(CV_File) as pdf:\n",
        "    for i in range (0,pages):\n",
        "        page=pdf.pages[i]\n",
        "        text=page.extract_text()\n",
        "        print (text)\n",
        "        Script.append(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hs99vtX0WvsE"
      },
      "source": [
        "Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6IjtMPIWsb9"
      },
      "outputs": [],
      "source": [
        "\n",
        "import re #regular expresion\n",
        "resumeText = re.sub('![A-Za-z1-9]', '  ', Script[0])\n",
        "resumeText=re.sub('\\n', '  ', resumeText)\n",
        "\n",
        "email=re.findall(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,7}\\b', resumeText)\n",
        "\n",
        "links=re.findall('http\\S+\\s*', resumeText)\n",
        "links2=re.findall('[A-Za-z]*.com',resumeText)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3sVcynSWsgA",
        "outputId": "b1c34b12-0afe-43d2-81ef-fcfb071a70cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DIVYANSHU\n",
            "EDUCATION\n",
            "COURSEWORK\n",
            "2023Web Development Bootcamp\n",
            "SKILLS\n",
            "PROJECTS\n",
            "POSITION OF RESPONSIBILITY\n",
            "Head Designer\n",
            "ACM-GEHU\n",
            "ACHIEVEMENTS\n"
          ]
        }
      ],
      "source": [
        "\n",
        "sections=[]\n",
        "for i in Script[0].split('\\n'):\n",
        "    if len((i.split())) <= 3 :\n",
        "        print (i)\n",
        "        sections.append(i)\n",
        "Name=sections[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-K7pt2leWsi4",
        "outputId": "8ca806de-f677-4c34-ee1f-731292844636"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "\n",
        "numeric_data=0\n",
        "for line in Script[0].split('\\n'):\n",
        "    for i in line.split():\n",
        "        if i.isdigit()==True :\n",
        "            numeric_data+=1;\n",
        "numeric_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vF0wcebUXJv5"
      },
      "outputs": [],
      "source": [
        "headings={'education' :1,'qualification' :1,'project':1,'skills':1,'relevant coursework':1,'achievement':1,'experience':1,'awards and honors':1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nz0PLx5_XTbG"
      },
      "outputs": [],
      "source": [
        "for i in sections:\n",
        "     i.lower()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbNxti7tXZrg"
      },
      "source": [
        "# loading Skills from JD and JD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARFxvAHCXTlS"
      },
      "outputs": [],
      "source": [
        "skills=['hello','Android']\n",
        "JD=\"JOB DESCRIPTION | Data Analyst  Job Title:  Data Analyst   Salary Grade (HR):   job Code:    FLSA Status (HR):  Non-Exempt Department Name:  Information Technology and Data  Approved By (HR):  Reports to (Title): Chief Operations Officer  Date Approved (HR): Date Prepared: October 11, 2016  Prepared By:  Teresa Mooney JOB SUMMARY: Under the supervision of the Chief Operations Officer, this vital role supports HOPES strategic business plan, agency data and reporting initiatives. This position has a specific focus on developing and coordinating systems and processes that engage and solicit data management and reporting analytics across the agency.   ESSENTIAL FUNCTIONS: Leadership | Identify, Evaluate & Utilizes Data | Data Project Management | Training & Development of Data Material Leadership 1.  Ability to capture vision, utilize great communication skills to collaborate and partner with multidisciplinary team members to help launch strategic data driven initiatives. 2.  Work closely with CEO and COO on business plan/ strategic plan 3.  Lead point of contact and subject matter expert for obtaining all data aspects of Community health and needs assessment  Identify, Evaluates & Utilizes Data   Identifies Data: 1.  Knowledgeable of the high level of reporting needed to provide data and capture big picture objectives  2.  Works closely with IT department in building of pertinent data for real time information (Dashboard) & reporting Evaluates Data: 1.  Understands what’s behind automation and entailed in building, revising & troubleshooting the reporting aspects of analytics 2.  Ability to help move forward and lead the Data Analyst metrics for Continuous Quality Improvement (CQI) initiatives  3.  Figure out how to mine information from clinical and operational data and distill best practices, enabling Care Team to create information-driven care plans in real time.  4.  Work closely with IT department to develop on demand data via Electronic Provider boards (Visual Dashboard) 5.  Reporting to improve population health and population medicine Utilizes Data:   1.  Work with PCMH team to submit PCMH application 2.  This entails possessing the knowledge base, to help teams recognize and identify what’s needed (required) to build and set up efficient workflow process   3.  Tracks the impact and results of pilot programs, determining which have the greatest measurable impact. 4.  Reviews process/workflow improvements based upon data collection & analysis  5.  Analyzes and develops Score Card metrics for providers  6.  Evaluates grant reporting requirements, analyzes process to collect data needed in order to produce accurate reporting.  7.  Develop reports to look at trends within agency, to guide programming  Data Project Management 1.  This entails possessing the knowledge base, to help teams recognize and identify what’s needed (required) to build and set up efficient workflow process 2.  Work with PCMH team to submit PCMH application  Training & Development of Data Material 1.  Presentation skills  and helps implement necessary information to Care Team  2.  To include presenting  training materials (FAQ, Fact Sheets, Cheat sheets) to end users that result in staff gaining daily proficiency and being empowered to adapt to ongoing changes     REQUIREMENTS: 1.  2-3 years’ experience in Data Analyst role/Communication with a savvy, enthusiastic and analytical mind; experience in healthcare and nonprofit sector a plus 2.  Ability to easily consume, process and analyze data, as well as to respond with appropriate strategies and tactics 3.  Ability to multitask and meet deadlines 4.  Ability to work autonomously as well as collaboratively, ready to produce results  MARGINAL/ADDITIONAL FUNCTIONS:  1.  Assist with other department activities as assigned 2.  Support other HOPES departments as needed    REPORTING STRUCTURE:   Supervision Received:     Reports to the Chief Operations Officer Supervision Exercised:    None Directly Reporting:      None Indirectly Reporting:     None  CONTACTS: Internal:   HOPES staff, volunteers and patients,  External:   donors, vendors, volunteers, and community  Education or equivalency:  Bachelor’s Degree in Business, Healthcare Management/Administration or 2-5 years’ experience in related field  Experience: 2-3 years’ experience in a Financial Analyst role in Healthcare or Non-profit setting  EMPLOYEE ACKNOWLEDGEMENT \";"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v09NhyQtXTnn"
      },
      "outputs": [],
      "source": [
        "\n",
        "Req_Clear=JD\n",
        "\n",
        "Match_Test=[resumeText,Req_Clear]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JPq5aIfavat"
      },
      "source": [
        "# Similarity BW JD and CV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-faxDxLtaxdl"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv=CountVectorizer()\n",
        "count_matrix=cv.fit_transform(Match_Test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeP6YHOgaxgY",
        "outputId": "ea75af64-154a-481f-bdc9-b16e5ec4b1e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity is : [[1.         0.39620809]\n",
            " [0.39620809 1.        ]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "print('Similarity is :',cosine_similarity(count_matrix))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SinN_RkbNiZ"
      },
      "source": [
        "# searching skills"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5mMVgoebJKY",
        "outputId": "7453fed9-9039-4f39-b24c-910025fca82d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "#skills search\n",
        "\n",
        "score=0;\n",
        "for i in skills:\n",
        "    mentions=re.findall(i, resumeText)\n",
        "    score=score+len(mentions)\n",
        "score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udscSQJLbX1j"
      },
      "source": [
        "# Grammer Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgSOTnsVbJNJ",
        "outputId": "d55c4b5f-2e2f-4368-893f-2bb098bf16dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: language-tool-python in /usr/local/lib/python3.11/dist-packages (2.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "pip install language-tool-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVRXfv22bfRr",
        "outputId": "8b3324bf-a40d-4ca2-a1ee-39cca59f8b9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: 3to2 in /usr/local/lib/python3.11/dist-packages (1.1.1)\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade 3to2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "3RyB6Ps9bfT6",
        "outputId": "40191b6a-183c-4c7e-ad21-32ed4abb828c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading LanguageTool 5.7: 153B [00:00, 203kB/s]\n",
            "INFO:language_tool_python.download_lt:Unzipping /tmp/tmpvnhaquvd.zip to /root/.cache/language_tool_python.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BadZipFile",
          "evalue": "File is not a zip file",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-adfcd07ae5d9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlanguage_tool_python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlanguage_tool_python\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLanguageTool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en-US'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/language_tool_python/server.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, language, motherTongue, remote_server, newSpellings, new_spellings_persist, host, config)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_remote_server_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_server_is_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_server_on_free_port\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlanguage\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/language_tool_python/server.py\u001b[0m in \u001b[0;36m_start_server_on_free_port\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'http://{}:{}/v2/'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_port\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_local_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mServerError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/language_tool_python/server.py\u001b[0m in \u001b[0;36m_start_local_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_start_local_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;31m# Before starting local server, download language tool if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mdownload_lt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/language_tool_python/download_lt.py\u001b[0m in \u001b[0;36mdownload_lt\u001b[0;34m()\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0mdownload_zip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage_tool_download_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/language_tool_python/download_lt.py\u001b[0m in \u001b[0;36mdownload_zip\u001b[0;34m(url, directory)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mdownloaded_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;31m# Extract zip file to path.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0munzip_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownloaded_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0;31m# Remove the temporary file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownloaded_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/language_tool_python/download_lt.py\u001b[0m in \u001b[0;36munzip_file\u001b[0;34m(temp_file, directory_to_extract_to)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;34m\"\"\" Unzips a .zip file to folder path. \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unzipping {} to {}.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory_to_extract_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory_to_extract_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1311\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1313\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1314\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1378\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
          ]
        }
      ],
      "source": [
        "\n",
        "import language_tool_python\n",
        "\n",
        "tool = language_tool_python.LanguageTool('en-US')\n",
        "i = 0\n",
        "\n",
        "# Path of file which needs to be checked\n",
        "\n",
        "for line in Script[0].split('\\n'):\n",
        "    matches = tool.check(line)\n",
        "    i = i + len(matches)\n",
        "# prints total mistakes which are found\n",
        "# from the document\n",
        "\n",
        "print(\"No. of mistakes found in document is \", i)\n",
        "print()\n",
        "\n",
        "# prints mistake one by one\n",
        "for mistake in matches:\n",
        "    print(mistake)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhQqbf1Rbxdf"
      },
      "source": [
        "# Ageing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcDsXHczbfd4",
        "outputId": "f818dda5-8e77-4a84-9d45-30da1fdd3476"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting datefinder\n",
            "  Downloading datefinder-0.7.3-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: regex>=2017.02.08 in /usr/local/lib/python3.11/dist-packages (from datefinder) (2024.11.6)\n",
            "Requirement already satisfied: python-dateutil>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from datefinder) (2.8.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from datefinder) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.4.2->datefinder) (1.17.0)\n",
            "Downloading datefinder-0.7.3-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: datefinder\n",
            "Successfully installed datefinder-0.7.3\n"
          ]
        }
      ],
      "source": [
        "pip install datefinder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLZIab_abfgP",
        "outputId": "047d9650-0221-4a19-bbd8-bc2cd2b5bc04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current date and time: 2025\n",
            "{}\n",
            "CPU times: user 359 µs, sys: 0 ns, total: 359 µs\n",
            "Wall time: 348 µs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from datetime import datetime\n",
        "\n",
        "# Get the current date and time\n",
        "current_datetime = (datetime.now().year)\n",
        "t1=str(current_datetime)\n",
        "t2=str(current_datetime-1)\n",
        "print(\"Current date and time:\", current_datetime)\n",
        "\n",
        "# Formatting a datetime object as a string\n",
        "# formatted_datetime = current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "time_SCORE=0;\n",
        "dist={}\n",
        "for line in Script[0].split('\\n'):\n",
        "    f=0\n",
        "    for word in line.split():\n",
        "#     cout<<word\n",
        "        if word==t1:\n",
        "            f=1;\n",
        "    for word in line.split('-'):\n",
        "        if word==t1:\n",
        "            f=1;\n",
        "    for word in line.split('/'):\n",
        "        if word==t1:\n",
        "            f=1;\n",
        "    if f==1:\n",
        "        for word in line.split():\n",
        "            if word in skills:\n",
        "                if word in dist:\n",
        "                    dist[word]=dist[word]+2\n",
        "                else:\n",
        "                    dist[word]=2\n",
        "\n",
        "    f1=0\n",
        "    for word in line.split():\n",
        "        if word==t2:\n",
        "            f1=1;\n",
        "    for word in line.split('-'):\n",
        "        if word==t2:\n",
        "            f1=1;\n",
        "    for word in line.split('/'):\n",
        "        if word==t2:\n",
        "            f1=1;\n",
        "    if f1==1:\n",
        "        for word in line.split():\n",
        "            if word in skills:\n",
        "                if word in dist:\n",
        "                    dist[word]=dist[word]+1\n",
        "                else:\n",
        "                    dist[word]=1\n",
        "print(dist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuYlIJ5Db8CP"
      },
      "source": [
        "#Skill Extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2hz-8VGcAUG",
        "outputId": "e36ee959-6061-4626-ed96-5918822550f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting en-core-web-lg==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XJBtUKScAeA",
        "outputId": "d424e060-3b6e-4987-be5b-d33e290a8a16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 7.78 s, sys: 1.11 s, total: 8.89 s\n",
            "Wall time: 16.3 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "skill_pattern_path = \"/content/jz_skill_patterns.jsonl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "QfSllM6dcAhz",
        "outputId": "75a233f2-c6ea-40e5-e31c-c4436bae76ed"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "[E007] 'entity_ruler' already exists in pipeline. Existing names: ['tok2vec', 'tagger', 'parser', 'senter', 'attribute_ruler', 'lemmatizer', 'ner', 'entity_ruler']",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36madd_pipe\u001b[0;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfactory_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponent_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE007\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponent_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m         \u001b[0;31m# Overriding pipe name in the config is not supported and will be ignored.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"name\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: [E007] 'entity_ruler' already exists in pipeline. Existing names: ['tok2vec', 'tagger', 'parser', 'senter', 'attribute_ruler', 'lemmatizer', 'ner', 'entity_ruler']"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "ruler = nlp.add_pipe(\"entity_ruler\")\n",
        "ruler.from_disk(skill_pattern_path)\n",
        "nlp.pipe_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hjk38SPncAq-",
        "outputId": "5eb464ce-f8ec-4315-b7e0-981e50d56ec8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 6.2 µs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "def get_skills(text):\n",
        "    doc = nlp(text)\n",
        "    myset = []\n",
        "    subset = []\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == \"SKILL\":\n",
        "            subset.append(ent.text)\n",
        "    myset.append(subset)\n",
        "    return subset\n",
        "\n",
        "\n",
        "def unique_skills(x):\n",
        "    return list(set(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLnLo7m0cZHq",
        "outputId": "a7508cd1-2d97-412d-fd19-b015ce522b93"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 2.23 s, sys: 299 ms, total: 2.53 s\n",
            "Wall time: 5.23 s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords  # Import the stopwords module\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Initialize the WordNet Lemmatizer\n",
        "lm = WordNetLemmatizer()\n",
        "\n",
        "import nltk\n",
        "\n",
        "# Download the WordNet resource\n",
        "nltk.download('wordnet')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pqvrvzw8cZQA",
        "outputId": "b9e7cac9-c218-409f-db7a-cb2cb0939dc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 3.3 s, sys: 161 ms, total: 3.46 s\n",
            "Wall time: 3.56 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "def preprocess_text(Txt):\n",
        "    # Remove special characters, URLs, mentions, and other non-alphanumeric characters\n",
        "    Txt = re.sub('(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt', \" \", Txt)\n",
        "\n",
        "    # Convert to lowercase and split into words\n",
        "    Txt = Txt.lower()\n",
        "    words = Txt.split()\n",
        "\n",
        "    # Lemmatize words and remove stopwords\n",
        "    words = [lm.lemmatize(word) for word in words if word not in set(stopwords.words(\"english\"))]\n",
        "\n",
        "    # Join the cleaned words back into a single string\n",
        "    cleaned_text = \" \".join(words)\n",
        "\n",
        "    return cleaned_text\n",
        "cleaned_resume_text = preprocess_text(resumeText)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLvNYl04chu2",
        "outputId": "3d586504-132c-45ea-a219-a9d434b0ba6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n",
            "CPU times: user 79.6 ms, sys: 3.98 ms, total: 83.6 ms\n",
            "Wall time: 98.7 ms\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spacy/pipeline/entityruler.py:405: UserWarning: [W036] The component 'entity_ruler' does not have any patterns defined.\n",
            "  warnings.warn(Warnings.W036.format(name=self.name))\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "skills = get_skills(cleaned_resume_text)\n",
        "unique_skills_list = unique_skills(skills)\n",
        "print(unique_skills_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGp2yrzZcrnl"
      },
      "source": [
        "# Recomendation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivia90TJciUa"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def cleanResume(txt):\n",
        "    cleanText = re.sub(r'http\\S+\\s', ' ', txt)  # Remove URLs\n",
        "    cleanText = re.sub(r'RT|cc', ' ', cleanText)  # Remove 'RT' and 'cc'\n",
        "    cleanText = re.sub(r'#\\S+\\s', ' ', cleanText)  # Remove hashtags\n",
        "    cleanText = re.sub(r'@\\S+', '  ', cleanText)  # Remove mentions\n",
        "    cleanText = re.sub(r'[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', cleanText)  # Remove punctuation\n",
        "    cleanText = re.sub(r'[^\\x00-\\x7f]', ' ', cleanText)  # Remove special characters\n",
        "    cleanText = re.sub(r'\\s+', ' ', cleanText)  # Remove extra whitespaces\n",
        "    return cleanText\n",
        "\n",
        "resumeText = cleanResume(resumeText)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "TN4VqG7AciWz",
        "outputId": "8c2d76f0-bb30-4220-d5f3-fcff8e336c7c"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'clf.pkl'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'clf.pkl'"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle\n",
        "\n",
        "# words into categorical values\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "\n",
        "\n",
        "# ['Data Science', 'HR', 'Advocate', 'Arts', 'Web Designing',\n",
        "#        'Mechanical Engineer', 'Sales', 'Health and fitness',\n",
        "#        'Civil Engineer', 'Java Developer', 'Business Analyst',\n",
        "#        'SAP Developer', 'Automation Testing', 'Electrical Engineering',\n",
        "#        'Operations Manager', 'Python Developer', 'DevOps Engineer',\n",
        "#        'Network Security Engineer', 'PMO', 'Database', 'Hadoop',\n",
        "#        'ETL Developer', 'DotNet Developer', 'Blockchain', 'Testing'],\n",
        "#       dtype=object)\n",
        "\n",
        "\n",
        "\n",
        "# Prediction System\n",
        "\n",
        "import pickle\n",
        "\n",
        "# Load the trained classifier\n",
        "clf = pickle.load(open('clf.pkl', 'rb'))\n",
        "tfidfd = pickle.load(open('tfidf.pkl', 'rb'))\n",
        "\n",
        "# Clean the input resume\n",
        "cleaned_resume = cleanResume(resumeText)\n",
        "\n",
        "# Transform the cleaned resume using the trained TfidfVectorizer\n",
        "input_features = tfidfd.transform([cleaned_resume])\n",
        "\n",
        "# Make the prediction using the loaded classifier\n",
        "prediction_id = clf.predict(input_features)[0]\n",
        "\n",
        "# Map category ID to category name\n",
        "\n",
        "category_mapping = {\n",
        "    15: {\n",
        "        \"Job Category\": \"Java Developer\",\n",
        "        \"Required Skills\": ['Java language', 'Spring Hibernate', 'RESTful API', 'Maven', 'Jenkins', 'JUnit']\n",
        "    },\n",
        "    23: {\n",
        "        \"Job Category\": \"Testing\",\n",
        "        \"Required Skills\": ['Software Testing', 'Test Automation', 'Quality Assurance', 'Load Testing', 'Selenium', 'Bug Tracking']\n",
        "    },\n",
        "    8: {\n",
        "        \"Job Category\": \"DevOps Engineer\",\n",
        "        \"Required Skills\": ['DevOps Tools', 'CI/CD', 'Containerization', 'Infrastructure as Code', 'Docker', 'Kubernetes']\n",
        "    },\n",
        "    20: {\n",
        "        \"Job Category\": \"Python Developer\",\n",
        "        \"Required Skills\": ['Python', 'Web Frameworks', 'Data Analysis', 'Django', 'Flask', 'Pandas']\n",
        "    },\n",
        "    24: {\n",
        "        \"Job Category\": \"Web Designing\",\n",
        "        \"Required Skills\": ['HTML', 'CSS', 'JavaScript', 'Responsive Design', 'UI/UX Design', 'Front-end Frameworks']\n",
        "    },\n",
        "    12: {\n",
        "        \"Job Category\": \"HR\",\n",
        "        \"Required Skills\": ['Recruitment', 'HR Policies', 'Employee Relations', 'Performance Management', 'HR Software', 'Training and Development']\n",
        "    },\n",
        "    13: {\n",
        "        \"Job Category\": \"Hadoop\",\n",
        "        \"Required Skills\": ['Hadoop Ecosystem', 'Big Data Processing', 'MapReduce', 'Spark', 'Hive', 'HBase']\n",
        "    },\n",
        "    3: {\n",
        "        \"Job Category\": \"Blockchain\",\n",
        "        \"Required Skills\": ['Blockchain Technology', 'Smart Contracts', 'Cryptocurrency', 'Ethereum', 'Hyperledger', 'Consensus Algorithms']\n",
        "    },\n",
        "    10: {\n",
        "        \"Job Category\": \"ETL Developer\",\n",
        "        \"Required Skills\": ['ETL Tools', 'Data Transformation', 'Data Warehousing', 'ETL Frameworks', 'Data Integration', 'Data Quality']\n",
        "    },\n",
        "    18: {\n",
        "        \"Job Category\": \"Operations Manager\",\n",
        "        \"Required Skills\": ['Operations Management', 'Process Optimization', 'Supply Chain', 'Project Management', 'Lean Six Sigma', 'Business Process Modeling']\n",
        "    },\n",
        "    6: {\n",
        "        \"Job Category\": \"Data Science\",\n",
        "        \"Required Skills\": ['Data Analysis', 'Machine Learning', 'Statistics', 'Deep Learning', 'Data Visualization', 'Natural Language Processing']\n",
        "    },\n",
        "    22: {\n",
        "        \"Job Category\": \"Sales\",\n",
        "        \"Required Skills\": ['Sales Techniques', 'Customer Relationship Management', 'Market Research', 'Negotiation Skills', 'Sales Analytics', 'Lead Generation']\n",
        "    },\n",
        "    16: {\n",
        "        \"Job Category\": \"Mechanical Engineer\",\n",
        "        \"Required Skills\": ['Mechanical Design', 'CAD', 'Thermodynamics', 'Finite Element Analysis', 'Product Lifecycle Management', 'Manufacturing Processes']\n",
        "    },\n",
        "    1: {\n",
        "        \"Job Category\": \"Arts\",\n",
        "        \"Required Skills\": ['Artistic Creativity', 'Visual Design', 'Art History', 'Illustration', 'Digital Art', 'Photography']\n",
        "    },\n",
        "    7: {\n",
        "        \"Job Category\": \"Database\",\n",
        "        \"Required Skills\": ['Database Management', 'SQL', 'Data Modeling', 'Database Administration', 'NoSQL Databases', 'Database Tuning']\n",
        "    },\n",
        "    11: {\n",
        "        \"Job Category\": \"Electrical Engineering\",\n",
        "        \"Required Skills\": ['Electrical Design', 'Circuit Analysis', 'Electromagnetism', 'Power Electronics', 'Control Systems', 'Digital Signal Processing']\n",
        "    },\n",
        "    14: {\n",
        "        \"Job Category\": \"Health and fitness\",\n",
        "        \"Required Skills\": ['Fitness Training', 'Nutrition', 'Physical Therapy', 'Sports Medicine', 'Exercise Physiology', 'Rehabilitation']\n",
        "    },\n",
        "    19: {\n",
        "        \"Job Category\": \"PMO\",\n",
        "        \"Required Skills\": ['Project Management', 'Process Governance', 'Stakeholder Communication', 'Risk Management', 'Agile Methodology', 'Program Management']\n",
        "    },\n",
        "    4: {\n",
        "        \"Job Category\": \"Business Analyst\",\n",
        "        \"Required Skills\": ['Business Analysis', 'Requirements Gathering', 'Data Modeling', 'Business Process Improvement', 'UML', 'Use Case Analysis']\n",
        "    },\n",
        "    9: {\n",
        "        \"Job Category\": \"DotNet Developer\",\n",
        "        \"Required Skills\": ['.NET Framework', 'C# Programming', 'ASP.NET', 'MVC Framework', 'Entity Framework', 'Web API Development']\n",
        "    },\n",
        "    2: {\n",
        "        \"Job Category\": \"Automation Testing\",\n",
        "        \"Required Skills\": ['Test Automation Tools', 'Scripting', 'Selenium', 'Load Testing', 'API Testing', 'Performance Testing']\n",
        "    },\n",
        "    17: {\n",
        "        \"Job Category\": \"Network Security Engineer\",\n",
        "        \"Required Skills\": ['Network Security', 'Firewall Configuration', 'Intrusion Detection', 'Security Policies', 'Penetration Testing', 'Security Auditing']\n",
        "    },\n",
        "    21: {\n",
        "        \"Job Category\": \"SAP Developer\",\n",
        "        \"Required Skills\": ['SAP ERP', 'ABAP Programming', 'SAP HANA', 'SAP Fiori', 'SAP Integration', 'SAP Security']\n",
        "    },\n",
        "    5: {\n",
        "        \"Job Category\": \"Civil Engineer\",\n",
        "        \"Required Skills\": ['Civil Engineering Design', 'Structural Analysis', 'Construction Management', 'Geotechnical Engineering', 'Project Planning', 'Environmental Engineering']\n",
        "    },\n",
        "    0: {\n",
        "        \"Job Category\": \"Advocate\",\n",
        "        \"Required Skills\": ['Legal Advocacy', 'Courtroom Litigation', 'Legal Research', 'Legal Writing', 'Client Counseling', 'Mediation']\n",
        "    },\n",
        "}\n",
        "category_name = category_mapping.get(prediction_id, \"Unknown\")\n",
        "\n",
        "print(\"Predicted Category:\", category_name)\n",
        "print(prediction_id)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}